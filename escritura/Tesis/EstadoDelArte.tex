\chapter{Estado del arte}\label{chapter:estado_del_arte}
Con el creciente uso de las imágenes médicas para el diagnóstico, planeamiento de tratamientos y estudios clínicos, se ha vuelto casi obligatoria la utilización de computadoras para asistir en el análisis de dichas imágenes. En este contexto, uno de los objetivos del diagnóstico asistido por computadoras es acelerar la obtención de resultados precisos \citep{Sharma2010}. Una de las etapas más importantes en este proceso es la segmentación, ya que las etapas posteriores dependen en gran medida de la precisión de sus resultados. Para la delineación de estructuras anatómicas y otras regiones de interés, pues, es necesario contar con algoritmos confiables.
El objetivo de este capítulo es presentar las etapas del procesamiento de imágenes y algunas estrategias de segmentación, así como un relevamiento general del estado del arte. En la Sección \ref{section:procesamiento} se describen las etapas del procesamiento de imágenes, enfocadas particularmente en su aplicación a la medicina. Finalmente en la Sección \ref{section:algoritmos} se realiza una revisión de los algoritmos de segmentación más comúnmente utilizados sobre imágenes médicas.

\section{Procesamiento de imágenes}\label{section:procesamiento}
Los sistemas de procesamiento de imágenes médicas posibilitan obtener información de interés a partir de estudios de diversa índole, lo que permite a los profesionales médicos mejorar la precisión de sus diagnósticos y planificar tratamientos o cirugías. El principal objetivo de estos sistemas es obtener una imagen de salida que sea una representación precisa de la señal de entrada, para luego analizarla y extraer de ella la mayor cantidad de información de diagnóstico posible \citep{dougherty2009digital}. Sin importar el dominio de análisis, el procesamiento de imágenes se compone en general de 5 etapas que se pueden observar en la Figura \ref{fig:etapas_del_procesamiento}.

\begin{figure}[H]
\centering
\includegraphics[scale=0.3]{images/procesamiento.png}
\caption{Etapas del procesamiento de imágenes}
\label{fig:etapas_del_procesamiento}
\end{figure}

La primera etapa del procesamiento de imágenes es la captura. En el ámbito médico existen diferentes modalidades de captura. Una de estas modalidades es la resonancia magnética (RM). La RM es una de las técnicas más utilizadas para el diagnóstico y seguimiento de distintas enfermedades \citep{prince2006medical}. En la Figura \ref{fig:scanner:mri} se puede observar un escáner de resonancia magnética.  En este tipo de modalidad se utilizan campos magnéticos muy potentes para alinear la magnetización nuclear de los átomos  de hidrógeno del agua en el cuerpo. Unos campos de radiofrecuencia (RF) se utilizan luego para alterar sistemáticamente el alineamiento de esa magnetización, provocando que los átomos de hidrógeno generen un campo magnético rotacional detectable por el escáner \citep{novelline2004squire}.

\begin{figure}[H]
\centering
\includegraphics[scale=0.3]{images/scanner.jpg}
\caption{Escáner de resonancia magnética}
\label{fig:scanner:mri}
\end{figure}

Esta es una técnica flexible y dinámica que permite obtener imágenes de contraste variable utilizando secuencias de pulso y ajustando los parámetros de captura de la imagen correspondientes al tiempo longitudinal (T1) y al tiempo transversal (T2). Las imágenes obtenidas mediante este procedimiento son generalmente eficientes para detectar anormalidades en el cerebro, durante las etapas tempranas de una enfermedad, así como también resultan excelentes para la detección de tumores cerebrales o infecciones. En particular, la RM es muy útil para detectar enfermedades en la materia blanca tales como esclerosis múltiple, encefalopatías, y encefalitis pos infecciosa. Los determinantes principales del contraste y la intensidad de la señal son los tiempos de T1 y T2. El contraste es diferente entre imágenes T1 y T2 y las lesiones patológicas pueden separarse en grupos de acuerdo a las características de las dos imágenes mencionadas (T1 y T2):


\begin{table}[H]
	\centering
	\begin{tabular}{c|c c}
	Patología & Contraste en T1 & Contraste en T2   \\ 
	\hline Masa solida & Brillante & Oscura  \\ 
	Grasa & Oscura & Brillante  \\ 
	Quiste &	Brillante &	Oscura  \\ 
	\end{tabular} 
\end{table}

También existen variantes además de las dos modalidades principales de RM: la modalidad FLAIR (Fluid Attenuated Inversion Recovery), que suprime la señal de los fluidos y permite, entre otras cosas, detectar placas de esclerosis múltiple en el cerebro y la RM con realce de contraste de Gadolinio (T1C) que constituye la modalidad estándar para la identificación de tumores \cite{scarabino2012imaging}. En la figura \ref{fig:mri_cortes} se pueden observar diferentes cortes de cada una de estas variantes.

\begin{figure}[H]
\centering
\includegraphics[scale=0.2]{images/t1_t2_flair.jpg}
\caption{Cortes de imágenes MR utilizando T1, FLAIR y T2}
\label{fig:mri_cortes}
\end{figure}

Otra técnica muy utilizada para la captura es la tomografía computada (TC). La palabra tomografía deriva de dos palabras griegas; tomos, que significa corte o sección y grafía, que significa descripción. Un escaneo de TC es una modalidad que utiliza rayos X para obtener información estructural sobre el cuerpo humano. Para realizar este escaneo se utiliza un dispositivo llamado tomógrafo (Figura \ref{fig:tomografo}).

\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{images/ge_ct_scanner.jpg}
\caption{Tomógrafo}
\label{fig:tomografo}
\end{figure}

El tomógrafo emite rayos X, que son ondas electromagnéticas. La base del funcionamiento de este mecanismo de captura se basa en la propiedad de la materia y los tejidos de absorber de manera diferente estos rayos \citep{prince2006medical}.
Cuando las ondas son disparadas al individuo, la radiación que no ha sido absorbida por la materia es recogida por los detectores del tomógrafo. De esta manera, tejidos densos como los huesos aparecen blancos debido a que el calcio tiene una tasa alta de absorción de los rayos. La grasa y otros tejidos blandos, como el cerebro o el hígado, aparecen grises. El aire no absorbe los rayos, por lo que las cavidades que contienen aire, como los pulmones, aparecen negras.

Las tomografías son eficientes en casos de trauma y proveen buen detalle óseo y gran sensibilidad para detectar hemorragias agudas. Se han vuelto una herramienta importante en la medicina para suplementar los rayos X tradicionales, los ultrasonidos y las resonancias magnéticas y, aunque es todavía una modalidad bastante costosa, se está estableciendo como el estándar para el diagnóstico de muchas enfermedades. Las tomografías computadas son particularmente utilizadas para el diagnóstico de enfermedades de partes del cuerpo como el cerebro (figura \ref{fig:tomografia_cerebral}), el hígado, el pecho, al abdomen, la pelvis y la columna \citep{sharma2010automated}.

\begin{figure}[H]
\centering
\includegraphics[scale=1]{images/Schiavo_catscan.jpg}
\caption{Tomografía cerebral}
\label{fig:tomografia_cerebral}
\end{figure}

Todos los métodos de captura introducen en la imagen resultante algún tipo de error. Los problemas más comunes encontrados en las tomografías y las resonancias magnéticas son el efecto de volumen parcial y el ruido. Estos errores son más o menos frecuentes dependiendo de la modalidad de captura de la imagen así como el área de aplicación. Por ejemplo, los efectos de volumen parcial son más comunes en capturas de imágenes de cerebro, mientras que en capturas de imágenes del tórax es corriente encontrar otros artefactos debido al movimiento del individuo.

El problema de volumen parcial es causado por la baja resolución del dispositivo de captura de la imagen. Las resoluciones bajas causan una difusión de la imagen de manera que las actividades altas son distribuidas a las zonas cercanas. En la figura \ref{fig:resolucion} la grilla representa la resolución del dispositivo de captura. En la figura de la izquierda se puede observar como uno de los puntos negros abarca parcialmente más de una unidad de la grilla. En la figura de la derecha podemos observar como ese punto es distribuido en las 4 unidades de la grilla pero con una intensidad menor.

\begin{figure}[H]
\centering
\includegraphics[scale=0.3]{images/resolution.png}
\caption{(a) Los puntos negros representan las zonas de actividad alta y la grilla la resolución del dispositivo de captura. (b) La representación de la imagen luego de la captura.}
\label{fig:resolucion}
\end{figure}

El efecto producido cuando una zona de interés se propaga a la zona de fondo es denominado spill-out. El efecto inverso, conocido como spill-in, es la contaminación de la representación del área de interés con valores del fondo. En la figura \ref{fig:spill}a se muestra un mapa de la distribución real de una región de interés. En \ref{fig:spill}b se muestra el efecto de spill out, donde el fondo es “contaminado” con valores de la región de interés. En \ref{fig:spill}c se muestra el efecto de spill in, donde la zona de interés es afectada por los valores del fondo. Se puede ver en la figura \ref{fig:spill}d como la imagen final tiene los bordes de la zona de interés poco definidos o difusos.

\begin{figure}[H]
\centering
\includegraphics[scale=0.2]{images/spill.jpg}
\caption{(a) Distribución real de la actividad en la imagen. (b) Spill-out. (c) Spill-in (d) Resultado de la medición de la imagen.}
\label{fig:spill}
\end{figure}

Cuando se realiza una captura de imagen hay factores que tienden a producir variaciones en el brillo pese a que esta variación no se corresponde con algo presente en el objeto que se está representando. Generalmente estas variaciones son aleatorias y no tienen un patrón definido. Esto provoca un deterioro en la calidad de la imagen y se hacen especialmente notorios cuando los objetos que se quieren representar son pequeños y tienen un contraste pobre. Estas variaciones se denominan ruido.

Habitualmente las imágenes médicas contienen ruido, y esta presencia le da a la imagen una apariencia moteada, granulada, o con efecto “nieve”. Si bien el ruido provoca que la imagen tenga una apariencia no deseable, su efecto es más perjudicial cuando se aplica algún algoritmo automático sobre la imagen para realizar análisis y asistir en diagnósticos. En particular, las imágenes con ruido pueden forzar al algoritmo de segmentación a detectar regiones de manera errónea.

Debido a estos errores introducidos por la captura mencionados anteriormente, es muy importante una etapa de pre-procesamiento de la imagen para intentar eliminar todos los errores posibles de las imágenes previa su entrada a los algoritmos de segmentación. La etapa de pre-procesamiento también tiene por objetivo realzar bordes entre estructuras de interés y/o mejorar algunas propiedades de la imagen, tales como brillo o contraste \citep{bankman2008handbook}

En una tercera etapa se realiza el procesamiento de la imagen utilizando algoritmos de segmentación. El propósito de esta etapa es dividir las imágenes en regiones de interés. Existen varios métodos de segmentación, y la elección de uno de estos métodos depende de las características del problema que se busca resolver. Las diferentes técnicas de segmentación más utilizadas en el estado del arte se analizan en detalle en la Sección \ref{section:algoritmos}.

Sobre las imágenes segmentadas es posible realizar una extracción de características de interés, como topología, geometría, textura y otros indicadores, dependiendo del dominio de aplicación. Estas características son utilizadas en una etapa posterior de análisis y reporte que resultan útiles para diagnosticar y ayudar en la toma de decisiones médicas \citep{pham2000current}.

\section{Algoritmos de segmentación}\label{section:algoritmos}
La segmentación de imágenes es un proceso a través del cual se divide una imagen en regiones con propiedades similares \citep{pham2000current}. Dichas propiedades son determinadas por el algoritmo utilizado para tal efecto, y pueden involucrar criterios basados en intensidades de gris, características de textura, color o contraste. El objetivo de la segmentación es simplificar o cambiar la representación de una imagen en información significativa y sencilla de analizar \citep{barghout2003perceptual}. Tradicionalmente, la salida de un algoritmo de segmentación consiste en una máscara booleana que representa con 1s los puntos de la imagen que pertenecen a la región de interés, y con 0s cualquier otro punto. En imágenes 2D, estos puntos son denominados píxeles, y en imágenes 3D se denominan voxels. Para simplificar, en las secciones siguientes hablaremos genéricamente de puntos de la imagen.

En particular, la segmentación de imágenes médicas se utiliza para estudiar estructuras anatómicas o patológicas tales como tumores, lesiones u otras anormalidades. También se aplica para medir el volumen de una región y estudiar, por ejemplo, el crecimiento o reducción de un tumor, y luego ayudar en la planificación de tratamientos de radioterapia y calcular dosis de radiación \citep{sharma2010automated}.

La segmentación es uno de los problemas más difíciles dentro del procesamiento de imágenes ya que la mayoría de los objetos reales tienen formas, bordes y morfología compleja \citep{wu2007segmentation}, ademas de tener que lidiar con los problemas comunes de procesamiento de imágenes como el ruido y los problemas de volumen parcial mencionados en la sección anterior. 
Los algoritmos de segmentación pueden dividirse en dos grandes grupos, los métodos supervisados, que requieren datos de entrenamientos que el algoritmo utiliza como referencia para realizar la segmentación, y los no supervisados, que son algoritmos automáticos que realizan un agrupamiento sin tener datos previos \citep{pham2000current}.
En las siguientes subsecciones se explicarán algunos de los principales algoritmos de segmentación relevados del estado del arte para cada grupo.

\subsection{No supervisados}
Los algoritmos de segmentación no supervisados consiguen realizar un agrupamiento sin interacción de un usuario para contar con datos de entrenamiento. Sin embargo, suele ser necesaria su intervención, ya sea para realizar la identificación inicial de las clases o para realizar una clasificación posterior, que permita asignar etiquetas a cada región segmentada \citep{clarke1995mri}.
Entre los algoritmos más relevantes podemos encontrar el de umbralado, K-means, Fuzzy C-means, crecimiento de regiones y modelos deformables. A continuación se detalla brevemente su funcionamiento y aplicaciones, en particular sobre imágenes médicas.

\subsubsection{Umbralado}
Los algoritmos de segmentación por umbralado,  thresholding en inglés, permiten dividir una imagen escalar en dos regiones de interés mediante la separación de las intensidades \citep{weszka1978survey}. Este tipo de enfoques busca determinar un valor de intensidad, denominado umbral, que es luego utilizado para separar las diferentes regiones que componen la imagen. La segmentación se logra agrupando todos los puntos con mayor intensidad al umbral en una clase, y los restantes en otra.

Los algoritmos por umbralado son simples pero efectivos para segmentar imágenes en las que las estructuras de interés cuentan con intensidades, o alguna otra característica cuantificable bien contrastada \citep{pham2000current}. Normalmente el umbral es introducido por el usuario, pero existen también algunos métodos que permiten obtener el umbral de manera automática \citep{sahoo1988survey}. Este tipo de enfoque es normalmente utilizado como paso inicial en las operaciones de procesamiento de imágenes, como en \citep{bao2003noise}, que utilizan un umbralado basado en ondas para reducir el ruido en imágenes de resonancia magnética.

La  principal limitación de los algoritmos tradicionales radica en que la imagen sólo se divide en dos clases, y en que no es aplicable a imágenes multiespectrales \citep{pham2000current}. Por otro lado, los algoritmos de umbralado no tienen en cuenta características espaciales de la imagen, lo que hace que sean más sensibles al ruido y a las inhomogeneidades que puedan presentar las intensidades. Por esta razón, se han propuesto variaciones al algoritmo clásico de umbralado para la segmentación de imágenes médicas, como en \citep{zhang2010fast} que utilizan un algoritmo de umbralado 3D adaptativo para segmentar los huesos en imágenes de CT, y en \citep{jiang2003adaptive} que proponen un umbralado adaptativo local guiado por conocimiento, para detectar vasos sanguíneos en imágenes de retina.

\subsubsection{Crecimiento de regiones}
Los algoritmos de segmentación por crecimiento de regiones permiten extraer una región conectada de una imagen basándose en algún criterio de homogeneidad predefinido \citep{haralick1985image}.

En su versión más simple, esta técnica se inicializa mediante la selección de uno o más puntos, denominados semillas, para cada región que se desea obtener. Luego se incorporan a la región todos los puntos conectados a cada semilla, que poseen características similares. El criterio de crecimiento es una función basada en las similitudes de las características de los puntos, y las características utilizadas para calcular estas similitudes dependen del objetivo del estudio.

Este método mejora respecto al umbralado, ya que tiene en cuenta la conexión espacial, aunque su principal desventaja es que por lo general se requiere la interacción manual del usuario para ubicar las semillas, aunque se han desarrollado algunos enfoques para asignar las semillas de manera automática, como en \citep{kumar2011texture} para tumores cerebrales, o en \citep{wu2008segmentation} para ubicar semillas automáticamente sobre órganos abdominales.

Al igual que los métodos de umbralado, los enfoques basados en crecimiento de regiones no suelen utilizarse por sí solos, sino integrados con otros enfoques de segmentación \citep{freixenet2002yet}.

\subsubsection{Modelos deformables}
Los algoritmos de segmentación por modelos deformables (también conocidos como contornos activos o Snakes, para imágenes 2D, o superficies activas, para imágenes 3D) trabajan deformando un contorno o superficie inicial cerrada, bajo la influencia de fuerzas internas y externas. Dichas fuerzas trabajan estirando o contrayendo este contorno o superficie hasta amoldarse al límite real de la región de interés.

Las fuerzas internas se calculan en base a las características propias del contorno o superficie, y son las que permiten que el contorno o superficie se mantenga suave y continua a medida que se deforma.  Las fuerzas externas son derivadas normalmente de la imagen y son las que atraen al contorno o superficie hacia los bordes de la región de interés. La forma final del contorno o superficie se obtiene minimizando una función de energía \citep{pham2000current}.

Las principales ventajas de los modelos deformables son su capacidad para obtener curvas o superficies paramétricas cerradas de manera directa a partir de las imágenes, y la incorporación de la restricción de suavidad y continuidad del contorno, que proporciona robustez ante la presencia de bordes espurios o con ruido.

Una de las principales desventajas de los esquemas tradicionales es la necesidad de un contorno o superficie inicial cercano al deseado. Ante este problema se han desarrollado varias alternativas que lo resuelven, como en \citep{cohen1991active}, que agregan una fuerza adicional que permite que el contorno inicial se infle como un globo hasta llegar a un borde bien marcado.

En el Capítulo \ref{chapter:metodos} se presenta en detalle este algoritmo, donde describimos además su implementación como último paso en la propuesta presentada.

\subsubsection{K-Means}
Este es un método de clustering o agrupamiento que busca clasificar n objetos en k grupos, donde k es una cantidad conocida a priori. Cada grupo debe tener un centroide que representa el valor medio de sus miembros, el cual inicialmente puede definirse manual o automáticamente. Luego, de manera iterativa, se determina la pertenenciade cada objeto a un cluster, asignándolo al grupo que tenga el centroide más cercano. Luego de asignados todos los objetos a un cluster, se recalculan los centroides, a partir de la media de los objetos pertenecientes a cada grupo. La implementación más común utiliza una técnica de refinamiento iterativo donde se intenta reducir una función de costo y se utiliza la distancia euclídea entre los puntos para definir la pertenencia a un grupo \citep{macqueen1967some}.
 
Este algoritmo se ha utilizado en \citep{juang2010mri} para detectar lesiones cerebrales en imágenes MRI cerebrales, y en \citep{dalmiya2012application} se ha utilizado  para detectar tumores en mamografías.

\subsubsection{Fuzzy C-Means}
Fuzzy C-Means es un algoritmo de clustering no supervisado que permite obtener segmentaciones difusas agrupando elementos similares en clusters. Un cluster es un conjunto de elementos que son afines entre sí. Una de las principales desventajas de los algoritmos de clustering tradicionales radica en que los mismos asumen que cada elemento pertenece inequívocamente a un cluster, ignorando si existe o no alguna similaridad con los demás miembros de otros clusters \citep{full1982fuzzy}. Una manera de modelar esta similaridad fue introducida en \citep{zadeh1965fuzzy}, y consiste en representar la semejanza de los puntos que se desean clusterizar con una función, cuyos valores están entre cero y uno. Basado en esta propuesta, y a diferencia de K-Means, en donde cada elemento pertenece o no a un cluster de manera determinante, en el método de Fuzzy C-Means cada elemento posee una probabilidad de pertenencia a cada uno de los clusters.

En el Capítulo \ref{section:segmentacion_fuzzy} se presenta una explicación detallada de Fuzzy C-Means y además se lo utiliza como primer paso en la propuesta de este trabajo.

\subsection{Supervisados}
Los algoritmos supervisados requieren datos de entrenamiento que se obtienen mediante segmentaciones realizadas manualmente, y que luego son utilizados como referencia para realizar nuevas segmentaciones de forma automática \citep{pham2000current}.

En general, los métodos supervisados son costosos, y resulta bastante difícil y a veces hasta imposible, seleccionar y etiquetar correctamente los datos de entrenamiento \citep{jain2000statistical}. Por otro lado, los datos de entrenamiento generados están asociados a un tipo de imagen en particular, por lo que el esfuerzo para entrenar el algoritmo no es reutilizable para distintos dominios \citep{sharma2010automated}.

A continuación se describen brevemente los principales algoritmos supervisados utilizados para la segmentación de imágenes médicas.

\subsubsection{Segmentación basada en atlas}
Un atlas está definido como la combinación de una plantilla que es generada utilizando información compilada de la anatomía a segmentar y una imagen segmentada. Luego de registrar la plantilla, esta es utilizada para segmentar la nueva imagen \citep{cabezas2011review}. Cuando se compara a otros métodos de segmentación, los basados en atlas tienen la capacidad de segmentar imágenes con una relación no bien definida entre regiones e intensidades de píxeles. Otra ventaja importante de este tipo de segmentación es su uso en la práctica clínica para diagnósticos asistidos, donde se utilizan generalmente para medir las formas de un objeto o detectar diferencias morfológicas entre un grupo de pacientes \citep{kalinic2009atlas}. Por otro lado, la principal desventaja es el tiempo, generalmente elevado, necesario para la construcción del atlas.
 
La segmentación basada en atlas ha sido utilizada en imágenes de resonancias magnéticas de próstatas \citep{gubern2009atlas, klein2007segmentation, martin2010automated} y también en imágenes de cerebros para fines tales como la detección de epilepsia \citep{nagsemi} y análisis de la materia blanca \citep{lawes2008atlas}.

\subsubsection{k-NN (k-vecinos más cercanos)}
La clasificación en k-vecinos más cercanos es un método basado en reconocimiento de patrones. Este método de segmentación consiste en asignar los puntos de la imagen a una clase, buscando ejemplos en los datos de entrenamiento, con valores similares dentro de un espacio de características predefinido. En este espacio, cada eje representa una de las características del punto, como por ejemplo, su ubicación espacial e intensidad. El conjunto de datos de entrenamiento consiste en muestras preclasificadas que son añadidas al espacio de características, de acuerdo a los valores de las mismas. Cada voxel de una imagen nueva es clasificado comparándolo con las K muestras de entrenamiento más cercanas a él, en términos de distancia euclídea, dentro del espacio de características. La clase más frecuente entre las K muestras de entrenamiento, es la clase que se asigna al punto \citep{anbeek2008automated}.

En \citep{jafari2003multiwavelet} se utiliza un clasificador histológico basado en k-NN, que ayuda a determinar el nivel de malignidad de tejidos cancerosos en pronósticos de cáncer de próstata. En \citep{li2012using} se considera un clasificador k-nn para diferenciar metástasis en los ganglios linfáticos de los no linfáticos.

\subsubsection{ANN (Redes neuronales artificiales)}
Las redes neuronales artificiales son modelos computacionales, inspirados en el sistema nervioso de los animales, que son capaces de realizar reconocimiento de patrones y aprendizaje de máquina. Estos modelos son multipropósito y tienen una base teórica fuerte y alto potencial para ser utilizados en cualquier disciplina, en particular en aplicaciones médicas. Las redes neuronales artificiales constan de capas de nodos interconectados por conexiones con peso. Estos pesos de las conexiones se ajustan cuando se realiza el entrenamiento de la red neuronal. Un entrenamiento exitoso normalmente finaliza con una red que puede ejecutar determinada tarea, tal como una predicción de un valor de salida, la clasificación de un objeto, la aproximación de una función o el reconocimiento de un patrón \citep{dayhoff2001artificial}.

En \citep{taher2011lung} se utilizan ANN para segmentar imágenes color de esputo para detectar cáncer pulmonar en etapas tempranas. En \citep{ayer2010breast} se usa una red neuronal, entrenada con varias mamografías consecutivas de pacientes individuales, para estimar con mayor exactitud el riesgo de cáncer de mamas.

\subsubsection{SVM (Support Vector Machine)}
Las SVMs son modelos de aprendizaje supervisado para realizar análisis de datos y reconocimiento de patrones. Generalmente son utilizados para clasificación y análisis de regresión. La idea principal de la SVM es obtener una superficie (o hiperplano) capaz de separar las diferentes clases en las que se puede agrupar una distribución de datos en un espacio N-dimensional, utilizando para ello un proceso de optimización basado en la obtención de vectores que definen los límites de las clases. Estos vectores se denominan normalmente vectores soporte o support vectors \citep{cortes1995support}. Si consideramos, para el caso de la segmentación binaria, a la imagen de entrada como dos conjuntos de vectores en un espacio N-dimensional, asociados cada uno a una etiqueta diferente, el objetivo del algoritmo SVM es construir un hiperplano de separación en ese espacio, el cual permita maximizar el margen de distancia entre ambos conjuntos de datos \citep{scholkopf1999advances}.

Este algoritmo de clasificación  se ha utilizado para análisis de diferentes imágenes médicas, como en \citep{el2002support}, donde se utiliza el algoritmo para detectar  microcalcificaciones en mamografías digitales o en \citep{maglogiannis2004characterization}, en el cual se aplica una metodología basada en SVMs para analizar y caracterizar imágenes digitales de lesiones de piel.
